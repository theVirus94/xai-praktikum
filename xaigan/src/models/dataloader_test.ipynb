{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.56s)\n",
      "creating index...\n",
      "index created!\n",
      "0\n",
      "torch.Size([1000, 3, 256, 256])\n",
      "1\n",
      "torch.Size([1000, 3, 256, 256])\n",
      "2\n",
      "torch.Size([1000, 3, 256, 256])\n",
      "3\n",
      "torch.Size([1000, 3, 256, 256])\n",
      "4\n",
      "torch.Size([952, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from configurations import configurations \n",
    "\n",
    "MS_COCO_CFG = configurations[\"datasets\"][\"MS_COCO\"]\n",
    "val_info     = MS_COCO_CFG[\"path\"]+\"/\"+MS_COCO_CFG[\"trainval_annotations\"]+\"/\"+\"instances_val2017.json\"\n",
    "val_image    = MS_COCO_CFG[\"path\"]+\"/\"+MS_COCO_CFG[\"val_images\"]\n",
    "COCO_CLASSES = MS_COCO_CFG[\"classes\"]\n",
    "\n",
    "\n",
    "class COCODetection(data.Dataset):\n",
    "    def __init__(self, image_path, info_file, has_gt=True):\n",
    "        self.root = image_path\n",
    "        self.coco = COCO(info_file)\n",
    "        self.ids = list(self.coco.imgToAnns.keys())  # 标签数\n",
    "\n",
    "        if len(self.ids) == 0 or not has_gt:  # 如果没有标签或者不需要GT，则直接使用image\n",
    "            self.ids = list(self.coco.imgs.keys())\n",
    "        \n",
    "        \n",
    "\n",
    "        self.has_gt = has_gt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        im, gt, h, w, num_crowds = self.pull_item(index)\n",
    "        return im\n",
    "\n",
    "    def pull_item(self, index):\n",
    "        img_id = self.ids[index]\n",
    "        #print(img_id)\n",
    "        if self.has_gt:\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "            target = self.coco.loadAnns(ann_ids)\n",
    "            #print(target[0])\n",
    "        else:\n",
    "            target = []\n",
    "        crowd = [x for x in target if ('iscrowd' in x and x['iscrowd'])]\n",
    "        #print(crowd)\n",
    "        target = [x for x in target if not ('iscrowd' in x and x['iscrowd'])]\n",
    "        #print(target)\n",
    "        #print('````````````````````````````````````````````````````````````````````')\n",
    "        num_crowds = len(crowd) \n",
    "\n",
    "        # This is so we ensure that all crowd annotations are at the end of the array\n",
    "        target += crowd\n",
    "        #print(self.coco.loadImgs(img_id))\n",
    "        file_name = self.coco.loadImgs(img_id)[0]['file_name']\n",
    "        path = osp.join(self.root, file_name)\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (256,256))\n",
    "        #print(img.shape)\n",
    "        height, width, _ = img.shape\n",
    "\n",
    "        #if len(target) > 0: \n",
    "        #masks = [self.coco.annToMask(obj).reshape(-1) for obj in target]\n",
    "        #print(mask)\n",
    "        #masks = np.vstack(masks)\n",
    "        #masks = masks.reshape(-1, height, width)\n",
    "        \n",
    "        return torch.from_numpy(img).permute(2, 1, 0), target,  height, width, num_crowds\n",
    "\n",
    "#.permute(1, 0, 2)\n",
    "if __name__=='__main__':\n",
    "    dataset = COCODetection(val_image, val_info)\n",
    "    loader = DataLoader(dataset,batch_size=1000)\n",
    "    for n, (img) in enumerate(loader):\n",
    "        print(n)\n",
    "        print(img.shape)\n",
    "        #img = np.uint8(img.squeeze().numpy().transpose(1, 0, 2))\n",
    "        \n",
    "        #gt, masks, num_crowds = label\n",
    "        #masks = masks.squeeze(0)\n",
    "        \"\"\"\n",
    "        for m in range(masks.size(0)):\n",
    "            mask = masks[m].numpy()\n",
    "            color = np.random.randint(0, 255)\n",
    "            channel = np.random.randint(0, 3)\n",
    "            y, x = np.where(mask == 1)\n",
    "            img[y, x, channel] = color\n",
    "        \"\"\"\n",
    "        #cv2.imshow('img', img)\n",
    "        #cv2.waitKey(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ee0e6c8122b822122945f0aa99c8ddb93a0e42aba2c8b354f9571c232759f8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
